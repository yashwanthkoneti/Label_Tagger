from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import (
    f1_score, precision_score, recall_score,
    hamming_loss, classification_report
)
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer

# Clean text 
def clean_text(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# Label parsing
def parse_multilabel(y):
    """
    Accepts:
    - list[str]
    - comma-separated string
    """
    if isinstance(y, list):
        return y
    if isinstance(y, str):
        return [x.strip() for x in y.split(",") if x.strip()]
    return []

# TF-IDF Baseline Class
class TfidfMultilabelBaseline:
    def __init__(
        self,
        df,
        text_cols,
        label_col,
        test_size=0.2,
        random_state=42,
        max_features=20000
    ):
        self.df = df.copy()
        self.text_cols = text_cols
        self.label_col = label_col
        self.test_size = test_size
        self.random_state = random_state
        self.max_features = max_features

    def prepare_data(self):
        # ---- concatenate text fields
        self.df["full_text"] = (
            self.df[self.text_cols]
            .fillna("")
            .agg(" ".join, axis=1)
            .apply(clean_text)
        )

        # ---- parse labels
        self.df["parsed_labels"] = self.df[self.label_col].apply(parse_multilabel)

        # ---- split
        self.train_df, self.test_df = train_test_split(
            self.df,
            test_size=self.test_size,
            random_state=self.random_state
        )

        # ---- binarize labels
        self.mlb = MultiLabelBinarizer()
        self.y_train = self.mlb.fit_transform(self.train_df["parsed_labels"])
        self.y_test = self.mlb.transform(self.test_df["parsed_labels"])
		
    def train(self):
        # ---- TF-IDF
        self.vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),
            min_df=3,
            max_df=0.9,
            max_features=self.max_features,
            sublinear_tf=True
        )

        X_train = self.vectorizer.fit_transform(self.train_df["full_text"])
        X_test = self.vectorizer.transform(self.test_df["full_text"])

        # ---- classifier (strong regularization)
        base_clf = LogisticRegression(
            max_iter=1000,
            C=0.1,
            class_weight="balanced",
            solver="liblinear"
        )

        self.clf = OneVsRestClassifier(base_clf)
        self.clf.fit(X_train, self.y_train)

        self.X_train = X_train
        self.X_test = X_test
		
	def evaluate(self):
        y_pred_train = self.clf.predict(self.X_train)
        y_pred_test = self.clf.predict(self.X_test)

        metrics = {
            "train_micro_f1": f1_score(self.y_train, y_pred_train, average="micro"),
            "test_micro_f1": f1_score(self.y_test, y_pred_test, average="micro"),
            "train_macro_f1": f1_score(self.y_train, y_pred_train, average="macro"),
            "test_macro_f1": f1_score(self.y_test, y_pred_test, average="macro"),
            "hamming_loss": hamming_loss(self.y_test, y_pred_test)
        }

        print("\n=== TF-IDF BASELINE METRICS ===")
        for k, v in metrics.items():
            print(f"{k}: {v:.4f}")

        print("\n=== PER-LABEL REPORT (TEST) ===")
        print(
            classification_report(
                self.y_test,
                y_pred_test,
                target_names=self.mlb.classes_,
                zero_division=0
            )
        )

        return metrics



if __name__ == "__main__":
    df = pd.read_csv("your_data.csv")

    tfidf_baseline = TfidfMultilabelBaseline(
        df=df,
        text_cols=["description", "action_summary"],  # extensible
        label_col="root_cause"
    )

    tfidf_baseline.prepare_data()
    tfidf_baseline.train()
    tfidf_metrics = tfidf_baseline.evaluate()


